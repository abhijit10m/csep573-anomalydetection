{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%pip install pandas\n",
    "%pip install kaleido\n",
    "%pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.stats import norm\n",
    "\n",
    "test_df = pd.read_csv('dataset/processed/test.csv')  \n",
    "train_df = pd.read_csv('dataset/processed/training.csv')  \n",
    "validation_df = pd.read_csv('dataset/processed/validation.csv') \n",
    "\n",
    "split = np.array_split(validation_df, 2)\n",
    "\n",
    "validation_df_error_means = split[0]\n",
    "validation_df_classification = split[1]\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(\n",
    "    x = train_df.timestamp,\n",
    "    y = train_df.value,\n",
    "    mode='lines',\n",
    "    name = 'Ground Truth'\n",
    ")\n",
    "layout = go.Layout(\n",
    "    title = 'Signal Value Plot',\n",
    "    xaxis = {'title' : \"Date\"},\n",
    "    yaxis = {'title' : \"Close\"}\n",
    ")\n",
    "fig = go.Figure(data=[trace1], layout=layout)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class AnomalyDetectionDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data, n_past=14, n_future=1):\n",
    "        self.n_future = n_future\n",
    "        self.n_past = n_past\n",
    "        self.x = []\n",
    "        self.actual = []\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        data_columns = ['value', 'predicted', \"is_anomaly\"]\n",
    "\n",
    "        x = data[data_columns].astype(float)\n",
    "        self.scaler = self.scaler.fit(x)\n",
    "        x_scaled = self.scaler.transform(x)\n",
    "\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        self.IsAnomaly = []\n",
    "\n",
    "        for i in range(self.n_past, len(x_scaled) - self.n_future + 1):\n",
    "            self.X.append(  torch.tensor(x_scaled[i - self.n_past:i, 0: 2])  )\n",
    "            self.Y.append(  torch.tensor(x_scaled[i: i + self.n_future, 0: 2 ])  )\n",
    "            self.IsAnomaly.append(  torch.tensor(x_scaled[i:i + self.n_future, 2])  )\n",
    "\n",
    "        assert len(self.X) == len(self.Y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"x\": self.X[idx],\n",
    "            \"y\": self.Y[idx],\n",
    "            \"is_anomaly\": self.IsAnomaly[idx]\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    x = []\n",
    "    y = []\n",
    "    is_anomaly = []\n",
    "\n",
    "    for item in batch:\n",
    "        x.append(item[\"x\"])\n",
    "        y.append(item[\"y\"])\n",
    "        is_anomaly.append(item[\"is_anomaly\"])\n",
    "\n",
    "    x = torch.nn.utils.rnn.pad_sequence(x, batch_first=True)\n",
    "    y = torch.nn.utils.rnn.pad_sequence(y, batch_first=True)\n",
    "    is_anomaly = torch.nn.utils.rnn.pad_sequence(is_anomaly, batch_first=True)\n",
    "\n",
    "    return {\n",
    "        \"x\": x,\n",
    "        \"y\": y,\n",
    "        \"is_anomaly\": is_anomaly\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
    "\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "\n",
    "class EncoderDecoderConvLSTM(nn.Module):\n",
    "    def __init__(self, nf, in_chan,height):\n",
    "        super(EncoderDecoderConvLSTM, self).__init__()\n",
    "\n",
    "        \"\"\" ARCHITECTURE \n",
    "\n",
    "        # Encoder (ConvLSTM)\n",
    "        # Encoder Vector (final hidden state of encoder)\n",
    "        # Decoder (ConvLSTM) - takes Encoder Vector as input\n",
    "        # Decoder (3D CNN) - produces regression predictions for our model\n",
    "\n",
    "        \"\"\"\n",
    "        self.height = height\n",
    "        self.encoder_1_convlstm = ConvLSTMCell(input_dim=in_chan,\n",
    "                                               hidden_dim=nf,\n",
    "                                               kernel_size=(3, 3),\n",
    "                                               bias=True)\n",
    "\n",
    "        self.encoder_2_convlstm = ConvLSTMCell(input_dim=nf,\n",
    "                                               hidden_dim=nf,\n",
    "                                               kernel_size=(3, 3),\n",
    "                                               bias=True)\n",
    "\n",
    "        self.decoder_1_convlstm = ConvLSTMCell(input_dim=nf,  # nf + 1\n",
    "                                               hidden_dim=nf,\n",
    "                                               kernel_size=(3, 3),\n",
    "                                               bias=True)\n",
    "\n",
    "        self.decoder_2_convlstm = ConvLSTMCell(input_dim=nf,\n",
    "                                               hidden_dim=nf,\n",
    "                                               kernel_size=(3, 3),\n",
    "                                               bias=True)\n",
    "\n",
    "        self.decoder_CNN = nn.Conv3d(in_channels=nf,\n",
    "                                     out_channels=1,\n",
    "                                     kernel_size=(1, self.height+2, 3),\n",
    "                                     padding=(0, 1, 1))\n",
    "        # self.fc1 = nn.Linear(14 * 3 * batch_len, 24)\n",
    "        # self.fc2 = nn.Linear(24, 12)\n",
    "        # self.fc3 = nn.Linear(12, batch_len)\n",
    "\n",
    "\n",
    "    def autoencoder(self, x, seq_len, future_step, h_t, c_t, h_t2, c_t2, h_t3, c_t3, h_t4, c_t4):\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        # encoder\n",
    "        for t in range(seq_len):\n",
    "            h_t, c_t = self.encoder_1_convlstm(input_tensor=x[:, t, :, :],\n",
    "                                               cur_state=[h_t, c_t])  # we could concat to provide skip conn here\n",
    "            h_t2, c_t2 = self.encoder_2_convlstm(input_tensor=h_t,\n",
    "                                                 cur_state=[h_t2, c_t2])  # we could concat to provide skip conn here\n",
    "\n",
    "        # encoder_vector\n",
    "        encoder_vector = h_t2\n",
    "\n",
    "        # decoder\n",
    "        for t in range(future_step):\n",
    "            h_t3, c_t3 = self.decoder_1_convlstm(input_tensor=encoder_vector,\n",
    "                                                 cur_state=[h_t3, c_t3])  # we could concat to provide skip conn here\n",
    "            h_t4, c_t4 = self.decoder_2_convlstm(input_tensor=h_t3,\n",
    "                                                 cur_state=[h_t4, c_t4])  # we could concat to provide skip conn here\n",
    "            encoder_vector = h_t4\n",
    "            outputs += [h_t4]  # predictions\n",
    "\n",
    "        outputs = torch.stack(outputs, 1) # torch.Size([1, 1, nf, 14, 2])\n",
    "        # print(outputs.shape)\n",
    "        outputs = outputs.permute(0, 2, 1, 3, 4) #torch.Size([1, nf, 1, 14, 2])\n",
    "        # print(outputs.shape)\n",
    "        outputs = self.decoder_CNN(outputs) # torch.Size([1, 1, 1, nf, 2])\n",
    "        # outputs = torch.flatten(outputs) # torch.Size([1, 1, 1, nf, 2])\n",
    "        outputs = torch.nn.Sigmoid()(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x, future_seq=0):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor:\n",
    "            5-D Tensor of shape (b, t, c, h, w)        #   batch, time, channel, height, width\n",
    "        \"\"\"\n",
    "\n",
    "        # find size of different input dimensions\n",
    "        b, seq_len, _, h, w = x.size()\n",
    "\n",
    "        # initialize hidden states\n",
    "        h_t, c_t = self.encoder_1_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
    "        h_t2, c_t2 = self.encoder_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
    "        h_t3, c_t3 = self.decoder_1_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
    "        h_t4, c_t4 = self.decoder_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
    "\n",
    "        # autoencoder forward\n",
    "        outputs = self.autoencoder(x, seq_len, future_seq, h_t, c_t, h_t2, c_t2, h_t3, c_t3, h_t4, c_t4)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "\n",
    "batch_len = 100\n",
    "input_channels = 1 # 1\n",
    "output_channels = 1 # 1\n",
    "height = 14 ## Number of previous datapoints to use\n",
    "width = 2 ## Number of features per datapoints\n",
    "\n",
    "\n",
    "losses = {\n",
    "    \"train\":[],\n",
    "    \"val\":[]\n",
    "}\n",
    "\n",
    "train_dataset = AnomalyDetectionDataset(train_df, n_past=height, n_future=output_channels)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_len, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "# use the first half of the normal dev data as the dev set for the LSTM\n",
    "split = np.array_split(validation_df, 2)\n",
    "val_data = split[0]\n",
    "val_dataset = AnomalyDetectionDataset(val_data, n_past=height,n_future=output_channels)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_len, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "val_data2 = split[1]\n",
    "val_dataset2 = AnomalyDetectionDataset(val_data2, n_past=height,n_future=output_channels)\n",
    "val_dataloader2 = torch.utils.data.DataLoader(\n",
    "    val_dataset2, batch_size=batch_len, shuffle=False, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "len_train = len(train_dataloader)\n",
    "len_val = len(val_dataloader)\n",
    "\n",
    "\n",
    "# instantiate model\n",
    "autoEncoder = EncoderDecoderConvLSTM(nf=64, in_chan=1, batch_len=batch_len)\n",
    "optimizer = torch.optim.Adam(autoEncoder.parameters(), lr=0.001)\n",
    "\n",
    "train_iter = cycle(train_dataloader)\n",
    "val_iter = cycle(val_dataloader)\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "    print(\"epoch\", epoch)\n",
    "    autoEncoder.train()\n",
    "    plot_loss = []\n",
    "    plot_val_loss = []\n",
    "\n",
    "    \n",
    "    for itr in range(len_train):\n",
    "\n",
    "        batch = next(train_iter, None)\n",
    "        loss = 0\n",
    "        input = torch.tile(batch['x'],(2,1,1))[:batch_len,:,:]\n",
    "        input = torch.unsqueeze(input, 1)\n",
    "        input = torch.unsqueeze(input, 1)\n",
    "        \n",
    "        pred = autoEncoder(input, output_channels).squeeze()\n",
    "        y = torch.tile(batch[\"y\"],(2,1,1))[:batch_len,:].squeeze()\n",
    "        loss = loss_function(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss =loss.item()/batch_len\n",
    "        plot_loss.append(train_loss)\n",
    "    print('epoch', epoch, 'train loss', sum(plot_loss)/len_train)\n",
    "    losses[\"train\"].append(plot_loss)\n",
    "    autoEncoder.eval()\n",
    "    for itr in range(len_val):\n",
    "        \n",
    "        batch = next(val_iter, None)\n",
    "        loss=0\n",
    "        input = torch.tile(batch['x'],(2,1,1))[:batch_len,:,:]\n",
    "        input = torch.unsqueeze(input, 1)\n",
    "        input = torch.unsqueeze(input, 1)\n",
    "\n",
    "        pred = autoEncoder(input, output_channels).squeeze()\n",
    "\n",
    "        y = torch.tile(batch[\"y\"],(2,1,1))[:batch_len,:].squeeze()\n",
    "\n",
    "        loss = loss_function(pred, y)\n",
    "        val_loss = loss.item()/batch_len\n",
    "        plot_val_loss.append(val_loss)\n",
    "    print('epoch', epoch, 'val loss', sum(plot_val_loss)/len_val)\n",
    "    losses[\"val\"].append(plot_val_loss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l)/len(l)\n",
    "\n",
    "train_losses = list(map(mean, losses[\"train\"]))\n",
    "val_losses = list(map(mean, losses[\"val\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = [i for i in range(100)]\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = epochs,\n",
    "    y = train_losses,\n",
    "    mode='lines',\n",
    "    name = 'train losses'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = epochs,\n",
    "    y = val_losses,\n",
    "    mode='lines',\n",
    "    name = 'val losses'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Trian vs Validation loss',\n",
    "    xaxis = {'title' : \"epoch\"},\n",
    "    yaxis = {'title' : \"loss\"}\n",
    ")\n",
    "fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoEncoder.state_dict(), \"models/convlstmae/100batch_100epoch_64hidden_14prev_1future_0_001lr_adam/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the best model\n",
    "model = EncoderDecoderConvLSTM(nf=64, in_chan=1, batch_len=batch_len)\n",
    "model.load_state_dict(torch.load(\"models/convlstmae/100batch_100epoch_64hidden_14prev_1future_0_001lr_adam/model.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_function,params):\n",
    "    \"\"\"\n",
    "    Returns error means, standard deviations, and loss\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "\n",
    "    errors = torch.tensor([])\n",
    "    batch_len = params[\"batch_len\"]\n",
    "    output_channels = params[\"output_channels\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            loss = 0\n",
    "            input = torch.tile(batch['x'],(2,1,1))[:batch_len,:,:]\n",
    "            input = torch.unsqueeze(input, 1)\n",
    "            input = torch.unsqueeze(input, 1)\n",
    "\n",
    "            pred = model(input, output_channels).squeeze()\n",
    "            y = torch.tile(batch[\"y\"],(2,1,1))[:batch_len,:].squeeze()\n",
    "            loss = loss_function(pred, y)\n",
    "            batch_errors = y - pred\n",
    "            errors = torch.cat([errors, batch_errors])\n",
    "\n",
    "            total_loss += loss.item()/batch_len\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(\"Loss:\", avg_loss)\n",
    "\n",
    "    errors_np = errors.numpy()\n",
    "    means = np.mean(errors_np, axis=0)\n",
    "    stds = np.std(errors_np, axis=0)\n",
    "    print(\"Error means:\", means)\n",
    "    print(\"Error standard deviations:\", stds)\n",
    "\n",
    "    return errors_np, means, stds, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateF1Score(log_likelihoods, value_threshold, is_anomaly, params):\n",
    "    \"\"\"\n",
    "    Precondition: log_likelihoods and is_anomaly should be sorted by predicted\n",
    "    \"\"\"\n",
    "    pred_is_anomaly = log_likelihoods[:,0] < value_threshold\n",
    "\n",
    "    is_anomaly = is_anomaly > 0\n",
    "    tp = sum(pred_is_anomaly & is_anomaly)\n",
    "    fp = sum(pred_is_anomaly & np.logical_not(is_anomaly))\n",
    "    fn = sum(np.logical_not(pred_is_anomaly) & is_anomaly)\n",
    "\n",
    "    best_f1 = tp / (tp + 1 / 2 * (fp + fn))\n",
    "    best_predicted_threshold = log_likelihoods[0,1]\n",
    "\n",
    "    for i in range(1, len(is_anomaly)):\n",
    "        if pred_is_anomaly[i - 1]:\n",
    "            if is_anomaly[i - 1]:\n",
    "                tp -= 1\n",
    "                fn += 1\n",
    "            else:\n",
    "                fp -= 1\n",
    "\n",
    "            f1 = tp / (tp + 1 / 2 * (fp + fn))\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_predicted_threshold = log_likelihoods[i,1]\n",
    "\n",
    "    return best_predicted_threshold, best_f1\n",
    "\n",
    "\n",
    "def calculateF1ScoreFromPredictedThreshold(\n",
    "    log_likelihoods, value_threshold, predicted_threshold, is_anomaly\n",
    "):\n",
    "    pred_is_anomaly = (\n",
    "        (log_likelihoods[:,0] < value_threshold)\n",
    "        & (log_likelihoods[:,1] >= predicted_threshold)\n",
    "    )\n",
    "\n",
    "    is_anomaly = is_anomaly > 0\n",
    "\n",
    "    tp = sum(pred_is_anomaly & is_anomaly)\n",
    "    fp = sum(pred_is_anomaly & np.logical_not(is_anomaly))\n",
    "    fn = sum(np.logical_not(pred_is_anomaly) & is_anomaly)\n",
    "\n",
    "    return tp / (tp + 1 / 2 * (fp + fn))\n",
    "\n",
    "\n",
    "def calculateLogLikelihoods(model, dataloader, loss_function,params):\n",
    "    errors_np, means, stds, avg_loss = evaluate(model, dataloader, loss_function,params)\n",
    "    return np.concatenate(([[float('-inf'),float('-inf')]], norm.logpdf(errors_np, loc=means, scale=stds))), errors_np, means, stds, avg_loss\n",
    "\n",
    "\n",
    "def determineClassificationThresholds(model, dataloader, loss_function,params):\n",
    "    \"\"\"\n",
    "    Returns the best f1, value threshold, and predicted threshold\n",
    "    \"\"\"\n",
    "    best_f1 = -1\n",
    "    batch_len = params[\"batch_len\"]\n",
    "    log_likelihoods, errors_np, means, stds, avg_loss = calculateLogLikelihoods(model, dataloader, loss_function,params)\n",
    "\n",
    "    indices = np.argsort(log_likelihoods, axis=0)[:,1]\n",
    "\n",
    "    is_anomaly = [float(\"-inf\")]\n",
    "\n",
    "    for batch in dataloader:\n",
    "        anomalies = torch.tile(batch['is_anomaly'],(2,1))[:batch_len,:]\n",
    "        is_anomaly += anomalies[:,0]\n",
    "    is_anomaly = np.array(is_anomaly)\n",
    "    \n",
    "    # sort log likelihoods and anomalies by predicted\n",
    "    log_likelihoods_sorted = log_likelihoods[indices]\n",
    "    is_anomaly_sorted = is_anomaly[indices]\n",
    "\n",
    "    for value_threshold in log_likelihoods_sorted[:,0]:\n",
    "        predicted_threshold, f1 = calculateF1Score(\n",
    "            log_likelihoods_sorted, value_threshold, is_anomaly_sorted, params\n",
    "        )\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_value_threshold = value_threshold\n",
    "            best_predicted_threshold = predicted_threshold\n",
    "\n",
    "    print(\"Best f1:\", best_f1)\n",
    "    print(\"Best value threshold:\", best_value_threshold)\n",
    "    print(\"Best predicted threshold:\", best_predicted_threshold)\n",
    "\n",
    "    f1 = calculateF1ScoreFromPredictedThreshold(\n",
    "        log_likelihoods,\n",
    "        best_value_threshold,\n",
    "        best_predicted_threshold,\n",
    "        is_anomaly,\n",
    "    )\n",
    "    print(\"Sanity check with method using predicted threshold:\", f1)\n",
    "\n",
    "    return best_f1, best_value_threshold, best_predicted_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l)/len(l)\n",
    "\n",
    "def train(epochs, model,optimizer,loss_function, len_train, len_val, train_iter, val_iter, params):\n",
    "\n",
    "\n",
    "    losses = {\n",
    "        \"train\":[],\n",
    "        \"val\":[]\n",
    "    }\n",
    "\n",
    "    batch_len = params[\"batch_len\"]\n",
    "    output_channels = params[\"output_channels\"]\n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch\", epoch)\n",
    "        model.train()\n",
    "        plot_loss = []\n",
    "        plot_val_loss = []\n",
    "        \n",
    "        \n",
    "        for itr in trange(len_train):\n",
    "\n",
    "            batch = next(train_iter, None)\n",
    "            loss = 0\n",
    "            input = torch.tile(batch['x'],(batch_len,1,1))[:batch_len,:,:]\n",
    "            input = torch.unsqueeze(input, 1)\n",
    "            input = torch.unsqueeze(input, 1)\n",
    "            \n",
    "            pred = model(input, output_channels).squeeze()\n",
    "            y = torch.tile(batch[\"y\"],(batch_len,1,1))[:batch_len,:].squeeze()\n",
    "            # print(input.shape)\n",
    "            # print(pred.shape)\n",
    "            # print(y.shape)\n",
    "            loss = loss_function(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss =loss.item()/batch_len\n",
    "            plot_loss.append(train_loss)\n",
    "        print('epoch', epoch, 'train loss', sum(plot_loss)/len_train)\n",
    "        losses[\"train\"].append(plot_loss)\n",
    "\n",
    "        model.eval()\n",
    "        for itr in trange(len_val):\n",
    "            \n",
    "            batch = next(val_iter, None)\n",
    "            loss=0\n",
    "            input = torch.tile(batch['x'],(batch_len,1,1))[:batch_len,:,:]\n",
    "            input = torch.unsqueeze(input, 1)\n",
    "            input = torch.unsqueeze(input, 1)\n",
    "\n",
    "            pred = model(input, params[\"output_channels\"]).squeeze()\n",
    "\n",
    "            y = torch.tile(batch[\"y\"],(batch_len,1,1))[:batch_len,:].squeeze()\n",
    "\n",
    "            loss = loss_function(pred, y)\n",
    "            val_loss = loss.item()/batch_len\n",
    "            plot_val_loss.append(val_loss)\n",
    "\n",
    "        print('epoch', epoch, 'val loss', sum(plot_val_loss)/len_val)\n",
    "        losses[\"val\"].append(plot_val_loss)\n",
    "\n",
    "\n",
    "    model_directory = \"models/convlstmae/{}batchlen_{}epoch_{}hidden_{}prev_{}future_{}lr_adam\" \\\n",
    "    .format(param[\"batch_len\"], param[\"epochs\"], param[\"nf\"], param[\"height\"], param[\"output_channels\"], param[\"lr\"])\n",
    "\n",
    "    model_file_name = model_directory + \"_model.pt\"\n",
    "    model_train_eval = model_directory + \"_train_eval_plot.jpeg\"\n",
    "    model_losses = model_directory + \"_loses\"\n",
    "\n",
    "    torch.save(model.state_dict(), model_file_name)\n",
    "\n",
    "\n",
    "    train_losses = list(map(mean, losses[\"train\"]))\n",
    "    val_losses = list(map(mean, losses[\"val\"]))\n",
    "\n",
    "\n",
    "    epochs = [i for i in range(epochs)]\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "        x = epochs,\n",
    "        y = train_losses,\n",
    "        mode='lines',\n",
    "        name = 'train losses'\n",
    "    )\n",
    "    trace2 = go.Scatter(\n",
    "        x = epochs,\n",
    "        y = val_losses,\n",
    "        mode='lines',\n",
    "        name = 'val losses'\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title = 'Trian vs Validation loss',\n",
    "        xaxis = {'title' : \"epoch\"},\n",
    "        yaxis = {'title' : \"loss\"}\n",
    "    )\n",
    "    fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
    "\n",
    "    fig.write_image(model_train_eval)\n",
    "\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def grid(params,results):\n",
    "    batch_len = params[\"batch_len\"]\n",
    "    epochs = params[\"epochs\"]\n",
    "    height = params[\"height\"] ## Number of previous datapoints to use\n",
    "    lr = params[\"lr\"]\n",
    "    nf = params[\"nf\"]\n",
    "    input_channels = 1 # 1\n",
    "    output_channels = 1 # 1\n",
    "    width = 2 ## Number of features per datapoints\n",
    "    \n",
    "\n",
    "    train_dataset = AnomalyDetectionDataset(train_df, n_past=height, n_future=output_channels)    \n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_len, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "    val_dataset_error_means = AnomalyDetectionDataset(validation_df_error_means, n_past=height,n_future=output_channels)\n",
    "    val_dataloader_error_means = torch.utils.data.DataLoader(\n",
    "        val_dataset_error_means, batch_size=batch_len, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "    val_dataset_classification = AnomalyDetectionDataset(validation_df_classification, n_past=height,n_future=output_channels)\n",
    "    val_dataloader_classification = torch.utils.data.DataLoader(\n",
    "        val_dataset_classification, batch_size=batch_len, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "    loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "    len_train = len(train_dataloader)\n",
    "    len_val = len(val_dataloader_error_means)\n",
    "\n",
    "    autoEncoder = EncoderDecoderConvLSTM(nf=nf, in_chan=input_channels,height=height)\n",
    "    optimizer = torch.optim.Adam(autoEncoder.parameters(), lr=lr)\n",
    "\n",
    "    train_iter = cycle(train_dataloader)\n",
    "    val_iter = cycle(val_dataloader_error_means)\n",
    "\n",
    "    train(epochs, autoEncoder, optimizer, loss_function,  len_train, len_val, train_iter, val_iter, params)\n",
    "\n",
    "    f1, value_threshold, predicted_threshold = determineClassificationThresholds(autoEncoder, val_dataloader_classification, loss_function,params)\n",
    "    \n",
    "    if f1 > results[\"best_f1_grid_search\"] :\n",
    "        results[\"best_f1_grid_search\"] = float(\"-inf\")\n",
    "        results[\"best_model_grid_search\"] = autoEncoder\n",
    "        results[\"best_params_grid_search\"] = params\n",
    "        results[\"best_value_threshold_grid_search\"] = value_threshold\n",
    "        results[\"predicted_threshold_grid_search\"] = predicted_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"best_f1_grid_search\" : float(\"-inf\"),\n",
    "    \"best_model_grid_search\" : None,\n",
    "    \"best_params_grid_search\" : None,\n",
    "    \"best_value_threshold_grid_search\" : None,\n",
    "    \"predicted_threshold_grid_search\" : None\n",
    "\n",
    "}\n",
    "params = {\n",
    "    \"height\": list(reversed([14,21,28,35])),\n",
    "    \"nf\": [8,32,64,128,256],\n",
    "    \"epochs\": [20],\n",
    "    # \"epochs\": [1,10,20,30,40,50],\n",
    "    \"output_channels\": [1],\n",
    "    \"lr\":[0.001,0.0005,0.0001,0.01,0.005],\n",
    "    \"batch_len\": list(reversed([1,20,25,30,35]))\n",
    "}\n",
    "\n",
    "best_params = {\n",
    "        \"lr\":params[\"lr\"][0],\n",
    "        \"batch_len\":params[\"batch_len\"][0],\n",
    "        \"nf\": params[\"nf\"][0],\n",
    "        \"height\": params[\"height\"][0],\n",
    "        \"epochs\": params[\"epochs\"][0],\n",
    "        \"output_channels\": params[\"output_channels\"][0]\n",
    "}\n",
    "\n",
    "for hyperparameter in params:\n",
    "    param = best_params.copy()\n",
    "    for hyperparameter_value in params[hyperparameter]:\n",
    "        prev_f1 = results[\"best_f1_grid_search\"]\n",
    "        param[hyperparameter] = hyperparameter_value\n",
    "        print(\"params:\", param)\n",
    "        losses = grid(param,results)\n",
    "        if results[\"best_f1_grid_search\"] > prev_f1:\n",
    "            best_params[hyperparameter] = hyperparameter_value\n",
    "        print(\"Best Params so far: \", best_params)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "046d879b6e7459529a7c7d726e9efdd4b369f8f6a030ca68704b9aaf6f849a26"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ComputerVisionCourse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
